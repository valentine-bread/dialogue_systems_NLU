{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip -qq install torchtext==0.3.1\n",
    "# !git clone https://github.com/MiuLab/SlotGated-SLU.git\n",
    "# !wget -qq https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week08_multitask/conlleval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch, random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor, LongTensor\n",
    "    DEVICE = torch.device('cuda:0')\n",
    "else:\n",
    "    from torch import FloatTensor, LongTensor\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size = 869\n",
      "Tags count = 121\n",
      "Intents count = 21\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "def read_dataset(path):\n",
    "    with open(os.path.join(path, 'seq.in')) as f_words, \\\n",
    "            open(os.path.join(path, 'seq.out')) as f_tags, \\\n",
    "            open(os.path.join(path, 'label')) as f_intents:\n",
    "        \n",
    "        return [\n",
    "            (words.strip().split(), tags.strip().split(), intent.strip()) \n",
    "            for words, tags, intent in zip(f_words, f_tags, f_intents)\n",
    "        ]\n",
    "train_data = read_dataset('SlotGated-SLU/data/atis/train/')\n",
    "val_data = read_dataset('SlotGated-SLU/data/atis/valid/')\n",
    "test_data = read_dataset('SlotGated-SLU/data/atis/test/')\n",
    "\n",
    "intent_to_example = {example[2]: example for example in train_data}\n",
    "# for example in intent_to_example.values():\n",
    "#     print('Intent:\\t', example[2])\n",
    "#     print('Text:\\t', '\\t'.join(example[0]))\n",
    "#     print('Tags:\\t', '\\t'.join(example[1]))\n",
    "#     print()\n",
    "    \n",
    "from torchtext.data import Field, LabelField, Example, Dataset, BucketIterator\n",
    "\n",
    "tokens_field = Field()\n",
    "tags_field = Field(unk_token=None)\n",
    "intent_field = LabelField()\n",
    "\n",
    "fields = [('tokens', tokens_field), ('tags', tags_field), ('intent', intent_field)]\n",
    "\n",
    "train_dataset = Dataset([Example.fromlist(example, fields) for example in train_data], fields)\n",
    "val_dataset = Dataset([Example.fromlist(example, fields) for example in val_data], fields)\n",
    "test_dataset = Dataset([Example.fromlist(example, fields) for example in test_data], fields)\n",
    "\n",
    "tokens_field.build_vocab(train_dataset)\n",
    "tags_field.build_vocab(train_dataset)\n",
    "intent_field.build_vocab(train_dataset)\n",
    "\n",
    "print('Vocab size =', len(tokens_field.vocab))\n",
    "print('Tags count =', len(tags_field.vocab))\n",
    "print('Intents count =', len(intent_field.vocab))\n",
    "\n",
    "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "    datasets=(train_dataset, val_dataset, test_dataset), batch_sizes=(32, 128, 128), \n",
    "    shuffle=True, device=DEVICE, sort=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedModel(nn.Module):\n",
    "    def __init__(self, vocab_size, intents_count, tags_count, emb_dim=64, lstm_hidden_dim=128, num_layers=1,  dropout_p=0.25, pad_idx = 0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embeddings_layer = nn.Embedding(vocab_size, emb_dim, padding_idx = pad_idx)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self._intents_lstm_layer = nn.LSTM(input_size=emb_dim, hidden_size=lstm_hidden_dim, bidirectional=True, num_layers=num_layers, batch_first=True, dropout = dropout_p if num_layers > 1 else 0)\n",
    "        self._tags_lstm_layer = nn.LSTM(input_size=emb_dim, hidden_size=lstm_hidden_dim, bidirectional=True, num_layers=num_layers, batch_first=True, dropout = dropout_p if num_layers > 1 else 0)\n",
    "        self._intents_out_layer = nn.Linear(lstm_hidden_dim * 2, intents_count)\n",
    "        self._tags_out_layer = nn.Linear(lstm_hidden_dim * 2, tags_count)       \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        projections = self.dropout(self.embeddings_layer(inputs))\n",
    "        output_lstm_intents, (final_hidden_state_intents, _) = self._intents_lstm_layer(projections)\n",
    "        output_lstm_tags, (final_hidden_state_tags, _) = self._tags_lstm_layer(projections)\n",
    "        \n",
    "        hidden = self.dropout(torch.cat([final_hidden_state_intents[0], final_hidden_state_intents[1]], dim=1))\n",
    "        output_intents = self._intents_out_layer(hidden)\n",
    "        \n",
    "        output_tags = self.dropout(output_lstm_tags)\n",
    "        output_tags = self._tags_out_layer(output_tags)\n",
    "        return (output_tags, output_intents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer_Trigger():\n",
    "    def __init__(self, model, criterion, criterion_ignore_pad, optimizer_tags, optimizer_intent, pad_idx):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.criterion_ignore_pad = criterion_ignore_pad\n",
    "        self.optimizer_tags = optimizer_tags\n",
    "        self.optimizer_intent = optimizer_intent\n",
    "        self.pad_idx = pad_idx\n",
    "        self.best_valid_loss = float('inf')\n",
    "        \n",
    "    def on_epoch_begin(self, is_train, name, batches_count):\n",
    "        \"\"\"\n",
    "        Initializes metrics\n",
    "        \"\"\"\n",
    "        self.epoch_loss = 0\n",
    "        self.correct_count, self.total_count = 0, 0\n",
    "        self.is_train = is_train\n",
    "        self.name = name\n",
    "        self.batches_count = batches_count\n",
    "        \n",
    "        self.model.train(is_train)\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Outputs final metrics\n",
    "        \"\"\"\n",
    "        valid_loss = self.epoch_loss / self.batches_count\n",
    "        if not(self.is_train) and valid_loss < self.best_valid_loss:\n",
    "            self.best_valid_loss = valid_loss\n",
    "            torch.save(self.model, 'AsynMultiTaskModel.pt')\n",
    "        return '{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "            self.name, self.epoch_loss / self.batches_count, self.correct_count / self.total_count\n",
    "        )\n",
    "        \n",
    "    def on_batch(self, batch):\n",
    "        \"\"\"\n",
    "        Performs forward and (if is_train) backward pass with optimization, updates metrics\n",
    "        \"\"\"\n",
    "        \n",
    "        logits = self.model(batch.tokens.transpose(0, 1))\n",
    "        \n",
    "        logits_intents = logits[1]\n",
    "        loss = self.criterion(logits_intents, batch.intent)\n",
    "        \n",
    "        if self.is_train:\n",
    "            loss.backward(retain_graph = True)\n",
    "            self.optimizer_intent.step()\n",
    "            self.optimizer_intent.zero_grad()\n",
    "        self.epoch_loss += loss.item()\n",
    "        \n",
    "        predicted_intent = logits_intents.argmax(dim=1)\n",
    "        self.total_count += predicted_intent.size(0)\n",
    "        self.correct_count += torch.sum(predicted_intent == batch.intent).item()\n",
    "        \n",
    "\n",
    "        logits_tags = logits[0].transpose(0, 1)  \n",
    "        logits_tags = logits_tags.reshape((-1,logits_tags.shape[2]))\n",
    "        tags = batch.tags.reshape((-1))\n",
    "        loss = self.criterion_ignore_pad(logits_tags, tags)\n",
    "        \n",
    "        if self.is_train:\n",
    "            loss.backward(retain_graph = True)\n",
    "            self.optimizer_tags.step()\n",
    "            self.optimizer_tags.zero_grad()\n",
    "        self.epoch_loss += loss.item()\n",
    "\n",
    "\n",
    "      \n",
    "        max_preds = logits_tags.argmax(dim = 1) \n",
    "        non_pad_elements = (tags != self.pad_idx).nonzero()\n",
    "        correct = torch.sum(max_preds[non_pad_elements] == tags[non_pad_elements]).item()\n",
    "        self.correct_count += correct\n",
    "        self.total_count += tags[non_pad_elements].shape[0]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "import math\n",
    "from tqdm import tqdm\n",
    "tqdm.get_lock().locks = []\n",
    "\n",
    "def do_epoch(trainer, data_iter, is_train, name=None):\n",
    "    trainer.on_epoch_begin(is_train, name, batches_count=len(data_iter))\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        with tqdm(total=trainer.batches_count) as progress_bar:\n",
    "            for i, batch in enumerate(data_iter):\n",
    "                batch_progress = trainer.on_batch(batch)\n",
    "\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description(batch_progress)\n",
    "                \n",
    "            epoch_progress = trainer.on_epoch_end()\n",
    "            progress_bar.set_description(epoch_progress)\n",
    "            progress_bar.refresh()\n",
    "\n",
    "            \n",
    "def fit(trainer, train_iter, epochs_count=1, val_iter=None):\n",
    "    best_val_loss = None\n",
    "    for epoch in range(epochs_count):\n",
    "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
    "        do_epoch(trainer, train_iter, is_train=True, name=name_prefix + 'Train:')\n",
    "        \n",
    "        if not val_iter is None:\n",
    "            do_epoch(trainer, val_iter, is_train=False, name=name_prefix + '  Val:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 30] Train: Loss = 2.66810, Accuracy = 70.12%: 100%|██████████| 140/140 [00:02<00:00, 69.65it/s]\n",
      "[1 / 30]   Val: Loss = 1.44941, Accuracy = 83.52%: 100%|██████████| 4/4 [00:00<00:00, 61.54it/s]\n",
      "[2 / 30] Train: Loss = 0.99398, Accuracy = 88.34%: 100%|██████████| 140/140 [00:01<00:00, 77.65it/s]\n",
      "[2 / 30]   Val: Loss = 0.82354, Accuracy = 91.05%: 100%|██████████| 4/4 [00:00<00:00, 75.47it/s]\n",
      "[3 / 30] Train: Loss = 0.62603, Accuracy = 92.79%: 100%|██████████| 140/140 [00:02<00:00, 65.03it/s]\n",
      "[3 / 30]   Val: Loss = 0.54641, Accuracy = 93.97%: 100%|██████████| 4/4 [00:00<00:00, 37.74it/s]\n",
      "[4 / 30] Train: Loss = 0.45622, Accuracy = 94.72%: 100%|██████████| 140/140 [00:02<00:00, 50.16it/s]\n",
      "[4 / 30]   Val: Loss = 0.45780, Accuracy = 95.23%: 100%|██████████| 4/4 [00:00<00:00, 36.04it/s]\n",
      "[5 / 30] Train: Loss = 0.33751, Accuracy = 96.07%: 100%|██████████| 140/140 [00:02<00:00, 50.78it/s]\n",
      "[5 / 30]   Val: Loss = 0.35902, Accuracy = 96.15%: 100%|██████████| 4/4 [00:00<00:00, 40.40it/s]\n",
      "[6 / 30] Train: Loss = 0.27457, Accuracy = 96.82%: 100%|██████████| 140/140 [00:02<00:00, 50.36it/s]\n",
      "[6 / 30]   Val: Loss = 0.30190, Accuracy = 96.95%: 100%|██████████| 4/4 [00:00<00:00, 38.83it/s]\n",
      "[7 / 30] Train: Loss = 0.21914, Accuracy = 97.43%: 100%|██████████| 140/140 [00:02<00:00, 51.00it/s]\n",
      "[7 / 30]   Val: Loss = 0.26012, Accuracy = 97.26%: 100%|██████████| 4/4 [00:00<00:00, 38.83it/s]\n",
      "[8 / 30] Train: Loss = 0.18048, Accuracy = 97.80%: 100%|██████████| 140/140 [00:02<00:00, 51.70it/s]\n",
      "[8 / 30]   Val: Loss = 0.24072, Accuracy = 97.66%: 100%|██████████| 4/4 [00:00<00:00, 38.46it/s]\n",
      "[9 / 30] Train: Loss = 0.15273, Accuracy = 98.21%: 100%|██████████| 140/140 [00:02<00:00, 51.66it/s]\n",
      "[9 / 30]   Val: Loss = 0.23398, Accuracy = 97.79%: 100%|██████████| 4/4 [00:00<00:00, 40.82it/s]\n",
      "[10 / 30] Train: Loss = 0.12396, Accuracy = 98.43%: 100%|██████████| 140/140 [00:02<00:00, 51.30it/s]\n",
      "[10 / 30]   Val: Loss = 0.23850, Accuracy = 97.97%: 100%|██████████| 4/4 [00:00<00:00, 40.82it/s]\n",
      "[11 / 30] Train: Loss = 0.10115, Accuracy = 98.62%: 100%|██████████| 140/140 [00:02<00:00, 51.66it/s]\n",
      "[11 / 30]   Val: Loss = 0.23006, Accuracy = 98.03%: 100%|██████████| 4/4 [00:00<00:00, 37.74it/s]\n",
      "[12 / 30] Train: Loss = 0.09161, Accuracy = 98.78%: 100%|██████████| 140/140 [00:02<00:00, 51.49it/s]\n",
      "[12 / 30]   Val: Loss = 0.20631, Accuracy = 98.10%: 100%|██████████| 4/4 [00:00<00:00, 38.83it/s]\n",
      "[13 / 30] Train: Loss = 0.07354, Accuracy = 98.95%: 100%|██████████| 140/140 [00:02<00:00, 51.28it/s]\n",
      "[13 / 30]   Val: Loss = 0.19534, Accuracy = 98.16%: 100%|██████████| 4/4 [00:00<00:00, 38.46it/s]\n",
      "[14 / 30] Train: Loss = 0.07424, Accuracy = 99.05%: 100%|██████████| 140/140 [00:02<00:00, 50.96it/s]\n",
      "[14 / 30]   Val: Loss = 0.21167, Accuracy = 98.21%: 100%|██████████| 4/4 [00:00<00:00, 40.40it/s]\n",
      "[15 / 30] Train: Loss = 0.06242, Accuracy = 99.13%: 100%|██████████| 140/140 [00:02<00:00, 50.17it/s]\n",
      "[15 / 30]   Val: Loss = 0.19613, Accuracy = 98.26%: 100%|██████████| 4/4 [00:00<00:00, 40.00it/s]\n",
      "[16 / 30] Train: Loss = 0.04891, Accuracy = 99.26%: 100%|██████████| 140/140 [00:02<00:00, 50.36it/s]\n",
      "[16 / 30]   Val: Loss = 0.18391, Accuracy = 98.50%: 100%|██████████| 4/4 [00:00<00:00, 36.70it/s]\n",
      "[17 / 30] Train: Loss = 0.04636, Accuracy = 99.33%: 100%|██████████| 140/140 [00:02<00:00, 50.71it/s]\n",
      "[17 / 30]   Val: Loss = 0.19624, Accuracy = 98.47%: 100%|██████████| 4/4 [00:00<00:00, 38.47it/s]\n",
      "[18 / 30] Train: Loss = 0.03976, Accuracy = 99.33%: 100%|██████████| 140/140 [00:02<00:00, 50.68it/s]\n",
      "[18 / 30]   Val: Loss = 0.20595, Accuracy = 98.48%: 100%|██████████| 4/4 [00:00<00:00, 39.22it/s]\n",
      "[19 / 30] Train: Loss = 0.04075, Accuracy = 99.47%: 100%|██████████| 140/140 [00:02<00:00, 50.83it/s]\n",
      "[19 / 30]   Val: Loss = 0.20040, Accuracy = 98.50%: 100%|██████████| 4/4 [00:00<00:00, 37.04it/s]\n",
      "[20 / 30] Train: Loss = 0.03471, Accuracy = 99.48%: 100%|██████████| 140/140 [00:02<00:00, 51.00it/s]\n",
      "[20 / 30]   Val: Loss = 0.18700, Accuracy = 98.60%: 100%|██████████| 4/4 [00:00<00:00, 39.60it/s]\n",
      "[21 / 30] Train: Loss = 0.03711, Accuracy = 99.56%: 100%|██████████| 140/140 [00:02<00:00, 50.52it/s]\n",
      "[21 / 30]   Val: Loss = 0.23224, Accuracy = 98.50%: 100%|██████████| 4/4 [00:00<00:00, 40.00it/s]\n",
      "[22 / 30] Train: Loss = 0.02804, Accuracy = 99.54%: 100%|██████████| 140/140 [00:02<00:00, 51.26it/s]\n",
      "[22 / 30]   Val: Loss = 0.19084, Accuracy = 98.55%: 100%|██████████| 4/4 [00:00<00:00, 42.09it/s]\n",
      "[23 / 30] Train: Loss = 0.02749, Accuracy = 99.58%: 100%|██████████| 140/140 [00:02<00:00, 51.21it/s]\n",
      "[23 / 30]   Val: Loss = 0.20467, Accuracy = 98.48%: 100%|██████████| 4/4 [00:00<00:00, 41.68it/s]\n",
      "[24 / 30] Train: Loss = 0.02517, Accuracy = 99.63%: 100%|██████████| 140/140 [00:02<00:00, 51.17it/s]\n",
      "[24 / 30]   Val: Loss = 0.19681, Accuracy = 98.50%: 100%|██████████| 4/4 [00:00<00:00, 40.01it/s]\n",
      "[25 / 30] Train: Loss = 0.02337, Accuracy = 99.62%: 100%|██████████| 140/140 [00:02<00:00, 50.95it/s]\n",
      "[25 / 30]   Val: Loss = 0.21977, Accuracy = 98.60%: 100%|██████████| 4/4 [00:00<00:00, 40.40it/s]\n",
      "[26 / 30] Train: Loss = 0.02120, Accuracy = 99.69%: 100%|██████████| 140/140 [00:02<00:00, 51.09it/s]\n",
      "[26 / 30]   Val: Loss = 0.21327, Accuracy = 98.56%: 100%|██████████| 4/4 [00:00<00:00, 37.38it/s]\n",
      "[27 / 30] Train: Loss = 0.01730, Accuracy = 99.73%: 100%|██████████| 140/140 [00:02<00:00, 50.65it/s]\n",
      "[27 / 30]   Val: Loss = 0.22079, Accuracy = 98.40%: 100%|██████████| 4/4 [00:00<00:00, 39.61it/s]\n",
      "[28 / 30] Train: Loss = 0.02191, Accuracy = 99.73%: 100%|██████████| 140/140 [00:02<00:00, 50.91it/s]\n",
      "[28 / 30]   Val: Loss = 0.21193, Accuracy = 98.60%: 100%|██████████| 4/4 [00:00<00:00, 40.82it/s]\n",
      "[29 / 30] Train: Loss = 0.01779, Accuracy = 99.75%: 100%|██████████| 140/140 [00:02<00:00, 51.06it/s]\n",
      "[29 / 30]   Val: Loss = 0.20864, Accuracy = 98.68%: 100%|██████████| 4/4 [00:00<00:00, 41.68it/s]\n",
      "[30 / 30] Train: Loss = 0.01682, Accuracy = 99.76%: 100%|██████████| 140/140 [00:02<00:00, 50.11it/s]\n",
      "[30 / 30]   Val: Loss = 0.20818, Accuracy = 98.71%: 100%|██████████| 4/4 [00:00<00:00, 41.65it/s]\n"
     ]
    }
   ],
   "source": [
    "tokens_pad_idx = tokens_field.vocab.stoi[tokens_field.pad_token]\n",
    "tags_pad_idx = tags_field.vocab.stoi[tags_field.pad_token]\n",
    "\n",
    "model = SharedModel(vocab_size=len(tokens_field.vocab), intents_count=len(intent_field.vocab), tags_count=len(tags_field.vocab), pad_idx = tokens_pad_idx).to(DEVICE)\n",
    "\n",
    "tags_parameters = [param for name, param in model.named_parameters() if not name.startswith('_intent')]\n",
    "intent_parameters = [param for name, param in model.named_parameters() if not name.startswith('_tags')]\n",
    "# print([name for name, param in model.named_parameters()])\n",
    "# print(len([name for name, param in model.named_parameters()]))\n",
    "# print(len(tags_parameters))\n",
    "# print(len(intent_parameters))\n",
    "\n",
    "criterion_ignore_pad = nn.CrossEntropyLoss(ignore_index=tags_pad_idx).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer_tags = optim.Adam(tags_parameters)\n",
    "optimizer_intent = optim.Adam(intent_parameters)\n",
    "\n",
    "trainer = ModelTrainer_Trigger(model, criterion, criterion_ignore_pad, optimizer_tags, optimizer_intent, tags_pad_idx)\n",
    "\n",
    "fit(trainer, train_iter, epochs_count=30, val_iter=val_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: Loss = 0.36012, Accuracy = 97.69%: 100%|██████████| 7/7 [00:00<00:00, 45.46it/s]\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('AsynMultiTaskModel.pt')\n",
    "\n",
    "do_epoch(trainer, test_iter, is_train=False, name='Test:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 94.83%, Recall = 93.95%, F1 = 94.39%\n",
      "Intent accuracy = 96.53%%\n"
     ]
    }
   ],
   "source": [
    "from conlleval import evaluate\n",
    "\n",
    "def eval_tagger(model, test_iter):\n",
    "    pad_idx = tags_field.vocab.stoi[tags_field.pad_token]\n",
    "    true_seqs, pred_seqs = [], []\n",
    "    correct_count, total_count = 0, 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_iter:\n",
    "            pred = model.forward(batch.tokens.transpose(0, 1))\n",
    "            \n",
    "            predicted_intent = pred[1].argmax(dim=1)\n",
    "            total_count += predicted_intent.size(0)\n",
    "            correct_count += torch.sum(predicted_intent == batch.intent).item()\n",
    "            \n",
    "            pred = pred[0].transpose(0, 1)\n",
    "            pred = pred.reshape((-1,pred.shape[2]))\n",
    "            true = batch.tags.reshape((-1))\n",
    "            \n",
    "            max_preds = pred.argmax(dim = 1)\n",
    "            non_pad_elements = (true != pad_idx).nonzero()\n",
    "            true = list(map(lambda y: tags_field.vocab.itos[y], true[non_pad_elements].reshape((-1))))\n",
    "            pred = list(map(lambda y: tags_field.vocab.itos[y], max_preds[non_pad_elements].reshape((-1))))\n",
    "            \n",
    "            \n",
    "            # print(true[200:220])\n",
    "            # print(pred[200:220])\n",
    "            # print()\n",
    "        \n",
    "            pred = ' '.join(pred)\n",
    "            true = ' '.join(true)\n",
    "        \n",
    "  \n",
    "            pred_seqs.append(pred)\n",
    "            true_seqs.append(true)\n",
    "            \n",
    "            \n",
    "    print('Precision = {:.2f}%, Recall = {:.2f}%, F1 = {:.2f}%'.format(*evaluate(true_seqs, pred_seqs, verbose=False)))\n",
    "    print('Intent accuracy = {:.2%}%'.format(correct_count / total_count))\n",
    "\n",
    "eval_tagger(model, test_iter)   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8cb139c522e4819e3d090dc8ad216bec05e65d93fe5d3ba0b78a4e6871c48307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
