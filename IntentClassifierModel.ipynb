{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" �� ���� ����७��� ��� ���譥�\n",
      "��������, �ᯮ��塞�� �ணࠬ��� ��� ������ 䠩���.\n"
     ]
    }
   ],
   "source": [
    "# !pip -qq install torchtext==0.3.1\n",
    "# !git clone https://github.com/MiuLab/SlotGated-SLU.git\n",
    "!wget -qq https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week08_multitask/conlleval.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Study\\Dialogue_systems\\env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor, LongTensor\n",
    "    DEVICE = torch.device('cuda:0')\n",
    "else:\n",
    "    from torch import FloatTensor, LongTensor\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "np.random.seed(42)\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent:\t atis_flight\n",
      "Text:\t is\tthere\ta\tdelta\tflight\tfrom\tdenver\tto\tsan\tfrancisco\n",
      "Tags:\t O\tO\tO\tB-airline_name\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tI-toloc.city_name\n",
      "\n",
      "Intent:\t atis_airfare\n",
      "Text:\t what\tis\tthe\tmost\texpensive\tone\tway\tfare\tfrom\tboston\tto\tatlanta\ton\tamerican\tairlines\n",
      "Tags:\t O\tO\tO\tB-cost_relative\tI-cost_relative\tB-round_trip\tI-round_trip\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tO\tB-airline_name\tI-airline_name\n",
      "\n",
      "Intent:\t atis_airline\n",
      "Text:\t list\tairlines\tserving\tbetween\tdenver\tand\tsan\tfrancisco\n",
      "Tags:\t O\tO\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tI-toloc.city_name\n",
      "\n",
      "Intent:\t atis_ground_service\n",
      "Text:\t tell\tme\tabout\tground\ttransportation\tbetween\torlando\tinternational\tand\torlando\n",
      "Tags:\t O\tO\tO\tO\tO\tO\tB-fromloc.airport_name\tI-fromloc.airport_name\tO\tB-toloc.city_name\n",
      "\n",
      "Intent:\t atis_quantity\n",
      "Text:\t how\tmany\tairlines\thave\tflights\twith\tservice\tclass\tyn\n",
      "Tags:\t O\tO\tO\tO\tO\tO\tO\tO\tB-fare_basis_code\n",
      "\n",
      "Intent:\t atis_city\n",
      "Text:\t where\tis\tlester\tpearson\tairport\n",
      "Tags:\t O\tO\tB-airport_name\tI-airport_name\tI-airport_name\n",
      "\n",
      "Intent:\t atis_flight#atis_airfare\n",
      "Text:\t all\tflights\tand\tfares\tfrom\tatlanta\tto\tdallas\tround\ttrip\tafter\t12\tpm\tless\tthan\t1100\tdollars\n",
      "Tags:\t O\tO\tO\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tB-round_trip\tI-round_trip\tB-depart_time.time_relative\tB-depart_time.time\tI-depart_time.time\tB-cost_relative\tO\tB-fare_amount\tI-fare_amount\n",
      "\n",
      "Intent:\t atis_abbreviation\n",
      "Text:\t what\tis\tfare\tcode\tm\n",
      "Tags:\t O\tO\tO\tO\tB-fare_basis_code\n",
      "\n",
      "Intent:\t atis_aircraft\n",
      "Text:\t i\twant\tto\tgo\tand\ttake\ta\tplane\tin\tatlanta\tand\tfly\tto\tboston\n",
      "Tags:\t O\tO\tO\tO\tO\tO\tO\tO\tO\tB-fromloc.city_name\tO\tO\tO\tB-toloc.city_name\n",
      "\n",
      "Intent:\t atis_distance\n",
      "Text:\t how\tfar\tis\tit\tfrom\torlando\tairport\tto\torlando\n",
      "Tags:\t O\tO\tO\tO\tO\tB-fromloc.airport_name\tI-fromloc.airport_name\tO\tB-toloc.city_name\n",
      "\n",
      "Intent:\t atis_ground_fare\n",
      "Text:\t what\tare\tthe\trental\tcar\trates\tin\tdallas\n",
      "Tags:\t O\tO\tO\tB-transport_type\tI-transport_type\tO\tO\tB-city_name\n",
      "\n",
      "Intent:\t atis_capacity\n",
      "Text:\t what\tis\tthe\tseating\tcapacity\tof\ta\tboeing\t767\n",
      "Tags:\t O\tO\tO\tO\tO\tO\tO\tO\tB-aircraft_code\n",
      "\n",
      "Intent:\t atis_flight_time\n",
      "Text:\t what\ttimes\tdoes\tcontinental\tdepart\tfrom\tboston\tto\tsan\tfrancisco\n",
      "Tags:\t O\tB-flight_time\tO\tB-airline_name\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tI-toloc.city_name\n",
      "\n",
      "Intent:\t atis_meal\n",
      "Text:\t what\tare\tall\tthe\tavailable\tmeals\n",
      "Tags:\t O\tO\tO\tO\tO\tB-meal\n",
      "\n",
      "Intent:\t atis_aircraft#atis_flight#atis_flight_no\n",
      "Text:\t i\twant\tto\tfly\tfrom\tdetroit\tto\tst.\tpetersburg\ton\tnorthwest\tairlines\tand\tleave\taround\t9\tam\ttell\tme\twhat\taircraft\tare\tused\tby\tthis\tflight\tand\ttell\tme\tthe\tflight\tnumber\n",
      "Tags:\t O\tO\tO\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tI-toloc.city_name\tO\tB-airline_name\tI-airline_name\tO\tO\tB-depart_time.time_relative\tB-depart_time.time\tI-depart_time.time\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\n",
      "\n",
      "Intent:\t atis_flight_no\n",
      "Text:\t i'm\ttrying\tto\tfind\tthe\tflight\tnumber\tfrom\ta\tflight\tfrom\torlando\tto\tcleveland\ton\tus\tair\tand\tit\tarrives\taround\t10\tpm\n",
      "Tags:\t O\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\tO\tB-airline_name\tI-airline_name\tO\tO\tO\tB-arrive_time.time_relative\tB-arrive_time.time\tI-arrive_time.time\n",
      "\n",
      "Intent:\t atis_restriction\n",
      "Text:\t what\tis\trestriction\tap80\n",
      "Tags:\t O\tO\tO\tB-restriction_code\n",
      "\n",
      "Intent:\t atis_airport\n",
      "Text:\t what's\tthe\tname\tof\tthe\tdenver\tairport\n",
      "Tags:\t O\tO\tO\tO\tO\tB-airport_name\tI-airport_name\n",
      "\n",
      "Intent:\t atis_airline#atis_flight_no\n",
      "Text:\t airline\tand\tflight\tnumber\tfrom\tcolumbus\tto\tminneapolis\n",
      "Tags:\t O\tO\tO\tO\tO\tB-fromloc.city_name\tO\tB-toloc.city_name\n",
      "\n",
      "Intent:\t atis_cheapest\n",
      "Text:\t show\tme\tthe\tcheapest\tfare\tin\tthe\tdatabase\n",
      "Tags:\t O\tO\tO\tB-cost_relative\tO\tO\tO\tO\n",
      "\n",
      "Intent:\t atis_ground_service#atis_ground_fare\n",
      "Text:\t what\tground\ttransportation\tis\tavailable\tfrom\tthe\tpittsburgh\tairport\tto\tdowntown\tand\thow\tmuch\tdoes\tit\tcost\n",
      "Tags:\t O\tO\tO\tO\tO\tO\tO\tB-fromloc.airport_name\tI-fromloc.airport_name\tO\tO\tO\tO\tO\tO\tO\tO\n",
      "\n",
      "Vocab size = 869\n",
      "Tags count = 121\n",
      "Intents count = 21\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "def read_dataset(path):\n",
    "    with open(os.path.join(path, 'seq.in')) as f_words, \\\n",
    "            open(os.path.join(path, 'seq.out')) as f_tags, \\\n",
    "            open(os.path.join(path, 'label')) as f_intents:\n",
    "        \n",
    "        return [\n",
    "            (words.strip().split(), tags.strip().split(), intent.strip()) \n",
    "            for words, tags, intent in zip(f_words, f_tags, f_intents)\n",
    "        ]\n",
    "train_data = read_dataset('SlotGated-SLU/data/atis/train/')\n",
    "val_data = read_dataset('SlotGated-SLU/data/atis/valid/')\n",
    "test_data = read_dataset('SlotGated-SLU/data/atis/test/')\n",
    "\n",
    "intent_to_example = {example[2]: example for example in train_data}\n",
    "for example in intent_to_example.values():\n",
    "    print('Intent:\\t', example[2])\n",
    "    print('Text:\\t', '\\t'.join(example[0]))\n",
    "    print('Tags:\\t', '\\t'.join(example[1]))\n",
    "    print()\n",
    "    \n",
    "from torchtext.data import Field, LabelField, Example, Dataset, BucketIterator\n",
    "\n",
    "tokens_field = Field()\n",
    "tags_field = Field(unk_token=None)\n",
    "intent_field = LabelField()\n",
    "\n",
    "fields = [('tokens', tokens_field), ('tags', tags_field), ('intent', intent_field)]\n",
    "\n",
    "train_dataset = Dataset([Example.fromlist(example, fields) for example in train_data], fields)\n",
    "val_dataset = Dataset([Example.fromlist(example, fields) for example in val_data], fields)\n",
    "test_dataset = Dataset([Example.fromlist(example, fields) for example in test_data], fields)\n",
    "\n",
    "tokens_field.build_vocab(train_dataset)\n",
    "tags_field.build_vocab(train_dataset)\n",
    "intent_field.build_vocab(train_dataset)\n",
    "\n",
    "print('Vocab size =', len(tokens_field.vocab))\n",
    "print('Tags count =', len(tags_field.vocab))\n",
    "print('Intents count =', len(intent_field.vocab))\n",
    "\n",
    "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "    datasets=(train_dataset, val_dataset, test_dataset), batch_sizes=(32, 128, 128), \n",
    "    shuffle=True, device=DEVICE, sort=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentClassifierModel(nn.Module):\n",
    "    def __init__(self, vocab_size, intents_count, emb_dim=64, lstm_hidden_dim=128, num_layers=1, dropout_p=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embeddings_layer = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.lstm_layer = nn.LSTM(input_size=emb_dim, hidden_size=lstm_hidden_dim, bidirectional=True, num_layers=num_layers, batch_first=True)\n",
    "        self.out_layer = nn.Linear(lstm_hidden_dim * 2, intents_count)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        projections = self.embeddings_layer(inputs)\n",
    "        _, (final_hidden_state, _) = self.lstm_layer(projections)\n",
    "        # print(output.shape)\n",
    "        hidden = self.dropout(torch.cat([final_hidden_state[0], final_hidden_state[1]], dim=1))\n",
    "        output = self.out_layer(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer():\n",
    "    def __init__(self, model, criterion, optimizer):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def on_epoch_begin(self, is_train, name, batches_count):\n",
    "        \"\"\"\n",
    "        Initializes metrics\n",
    "        \"\"\"\n",
    "        self.epoch_loss = 0\n",
    "        self.correct_count, self.total_count = 0, 0\n",
    "        self.is_train = is_train\n",
    "        self.name = name\n",
    "        self.batches_count = batches_count\n",
    "        \n",
    "        self.model.train(is_train)\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Outputs final metrics\n",
    "        \"\"\"\n",
    "        return '{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "            self.name, self.epoch_loss / self.batches_count, self.correct_count / self.total_count\n",
    "        )\n",
    "        \n",
    "    def on_batch(self, batch):\n",
    "        \"\"\"\n",
    "        Performs forward and (if is_train) backward pass with optimization, updates metrics\n",
    "        \"\"\"\n",
    "        logits = self.model(batch.tokens.transpose(0, 1))\n",
    "\n",
    "        loss = self.criterion(logits, batch.intent)\n",
    "        \n",
    "        predicted_intent = logits.argmax(dim=1)\n",
    "        self.total_count += predicted_intent.size(0)\n",
    "        self.correct_count += torch.sum(predicted_intent == batch.intent).item()\n",
    "\n",
    "        if self.is_train:\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "        self.epoch_loss += loss.item()\n",
    "        \n",
    "import math\n",
    "from tqdm import tqdm\n",
    "tqdm.get_lock().locks = []\n",
    "\n",
    "\n",
    "def do_epoch(trainer, data_iter, is_train, name=None):\n",
    "    trainer.on_epoch_begin(is_train, name, batches_count=len(data_iter))\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        with tqdm(total=trainer.batches_count) as progress_bar:\n",
    "            for i, batch in enumerate(data_iter):\n",
    "                batch_progress = trainer.on_batch(batch)\n",
    "\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description(batch_progress)\n",
    "                \n",
    "            epoch_progress = trainer.on_epoch_end()\n",
    "            progress_bar.set_description(epoch_progress)\n",
    "            progress_bar.refresh()\n",
    "\n",
    "            \n",
    "def fit(trainer, train_iter, epochs_count=1, val_iter=None):\n",
    "    best_val_loss = None\n",
    "    for epoch in range(epochs_count):\n",
    "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
    "        do_epoch(trainer, train_iter, is_train=True, name=name_prefix + 'Train:')\n",
    "        \n",
    "        if not val_iter is None:\n",
    "            do_epoch(trainer, val_iter, is_train=False, name=name_prefix + '  Val:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 30] Train: Loss = 0.85578, Accuracy = 80.42%: 100%|██████████| 140/140 [00:01<00:00, 78.96it/s]\n",
      "[1 / 30]   Val: Loss = 0.50997, Accuracy = 86.20%: 100%|██████████| 4/4 [00:00<00:00, 65.57it/s]\n",
      "[2 / 30] Train: Loss = 0.33923, Accuracy = 91.54%: 100%|██████████| 140/140 [00:01<00:00, 88.33it/s]\n",
      "[2 / 30]   Val: Loss = 0.35395, Accuracy = 90.80%: 100%|██████████| 4/4 [00:00<00:00, 85.10it/s]\n",
      "[3 / 30] Train: Loss = 0.22028, Accuracy = 93.84%: 100%|██████████| 140/140 [00:03<00:00, 40.09it/s]\n",
      "[3 / 30]   Val: Loss = 0.27404, Accuracy = 93.60%: 100%|██████████| 4/4 [00:00<00:00, 28.99it/s]\n",
      "[4 / 30] Train: Loss = 0.14592, Accuracy = 96.63%: 100%|██████████| 140/140 [00:03<00:00, 36.89it/s]\n",
      "[4 / 30]   Val: Loss = 0.16378, Accuracy = 96.60%: 100%|██████████| 4/4 [00:00<00:00, 28.99it/s]\n",
      "[5 / 30] Train: Loss = 0.09971, Accuracy = 97.54%: 100%|██████████| 140/140 [00:03<00:00, 36.03it/s]\n",
      "[5 / 30]   Val: Loss = 0.16109, Accuracy = 96.40%: 100%|██████████| 4/4 [00:00<00:00, 29.41it/s]\n",
      "[6 / 30] Train: Loss = 0.06231, Accuracy = 98.68%: 100%|██████████| 140/140 [00:03<00:00, 36.23it/s]\n",
      "[6 / 30]   Val: Loss = 0.15834, Accuracy = 96.60%: 100%|██████████| 4/4 [00:00<00:00, 28.57it/s]\n",
      "[7 / 30] Train: Loss = 0.04323, Accuracy = 99.11%: 100%|██████████| 140/140 [00:03<00:00, 36.66it/s]\n",
      "[7 / 30]   Val: Loss = 0.13575, Accuracy = 97.20%: 100%|██████████| 4/4 [00:00<00:00, 27.21it/s]\n",
      "[8 / 30] Train: Loss = 0.03798, Accuracy = 99.11%: 100%|██████████| 140/140 [00:03<00:00, 36.53it/s]\n",
      "[8 / 30]   Val: Loss = 0.19637, Accuracy = 96.20%: 100%|██████████| 4/4 [00:00<00:00, 28.17it/s]\n",
      "[9 / 30] Train: Loss = 0.02987, Accuracy = 99.33%: 100%|██████████| 140/140 [00:03<00:00, 36.34it/s]\n",
      "[9 / 30]   Val: Loss = 0.14977, Accuracy = 97.20%: 100%|██████████| 4/4 [00:00<00:00, 29.85it/s]\n",
      "[10 / 30] Train: Loss = 0.02348, Accuracy = 99.51%: 100%|██████████| 140/140 [00:03<00:00, 36.96it/s]\n",
      "[10 / 30]   Val: Loss = 0.14234, Accuracy = 97.20%: 100%|██████████| 4/4 [00:00<00:00, 28.37it/s]\n",
      "[11 / 30] Train: Loss = 0.01490, Accuracy = 99.71%: 100%|██████████| 140/140 [00:03<00:00, 36.64it/s]\n",
      "[11 / 30]   Val: Loss = 0.14567, Accuracy = 97.00%: 100%|██████████| 4/4 [00:00<00:00, 31.75it/s]\n",
      "[12 / 30] Train: Loss = 0.00831, Accuracy = 99.89%: 100%|██████████| 140/140 [00:03<00:00, 37.12it/s]\n",
      "[12 / 30]   Val: Loss = 0.13144, Accuracy = 98.20%: 100%|██████████| 4/4 [00:00<00:00, 32.79it/s]\n",
      "[13 / 30] Train: Loss = 0.00579, Accuracy = 99.96%: 100%|██████████| 140/140 [00:03<00:00, 36.86it/s]\n",
      "[13 / 30]   Val: Loss = 0.14015, Accuracy = 98.00%: 100%|██████████| 4/4 [00:00<00:00, 30.07it/s]\n",
      "[14 / 30] Train: Loss = 0.00467, Accuracy = 99.91%: 100%|██████████| 140/140 [00:03<00:00, 36.74it/s]\n",
      "[14 / 30]   Val: Loss = 0.15476, Accuracy = 97.00%: 100%|██████████| 4/4 [00:00<00:00, 29.20it/s]\n",
      "[15 / 30] Train: Loss = 0.00404, Accuracy = 99.93%: 100%|██████████| 140/140 [00:03<00:00, 36.83it/s]\n",
      "[15 / 30]   Val: Loss = 0.14565, Accuracy = 97.60%: 100%|██████████| 4/4 [00:00<00:00, 30.53it/s]\n",
      "[16 / 30] Train: Loss = 0.00341, Accuracy = 99.96%: 100%|██████████| 140/140 [00:03<00:00, 35.63it/s]\n",
      "[16 / 30]   Val: Loss = 0.15529, Accuracy = 96.60%: 100%|██████████| 4/4 [00:00<00:00, 26.49it/s]\n",
      "[17 / 30] Train: Loss = 0.00300, Accuracy = 99.98%: 100%|██████████| 140/140 [00:02<00:00, 67.18it/s]\n",
      "[17 / 30]   Val: Loss = 0.17240, Accuracy = 96.80%: 100%|██████████| 4/4 [00:00<00:00, 66.67it/s]\n",
      "[18 / 30] Train: Loss = 0.00283, Accuracy = 100.00%: 100%|██████████| 140/140 [00:01<00:00, 89.34it/s]\n",
      "[18 / 30]   Val: Loss = 0.15737, Accuracy = 96.80%: 100%|██████████| 4/4 [00:00<00:00, 61.54it/s]\n",
      "[19 / 30] Train: Loss = 0.00163, Accuracy = 100.00%: 100%|██████████| 140/140 [00:01<00:00, 89.80it/s]\n",
      "[19 / 30]   Val: Loss = 0.15641, Accuracy = 96.80%: 100%|██████████| 4/4 [00:00<00:00, 70.18it/s]\n",
      "[20 / 30] Train: Loss = 0.00167, Accuracy = 99.96%: 100%|██████████| 140/140 [00:01<00:00, 87.72it/s]\n",
      "[20 / 30]   Val: Loss = 0.16151, Accuracy = 96.80%: 100%|██████████| 4/4 [00:00<00:00, 66.67it/s]\n",
      "[21 / 30] Train: Loss = 0.00131, Accuracy = 100.00%: 100%|██████████| 140/140 [00:01<00:00, 87.88it/s]\n",
      "[21 / 30]   Val: Loss = 0.17081, Accuracy = 96.60%: 100%|██████████| 4/4 [00:00<00:00, 74.07it/s]\n",
      "[22 / 30] Train: Loss = 0.00097, Accuracy = 100.00%: 100%|██████████| 140/140 [00:01<00:00, 83.83it/s]\n",
      "[22 / 30]   Val: Loss = 0.17649, Accuracy = 96.80%: 100%|██████████| 4/4 [00:00<00:00, 108.10it/s]\n",
      "[23 / 30] Train: Loss = 0.00121, Accuracy = 99.98%: 100%|██████████| 140/140 [00:01<00:00, 107.60it/s]\n",
      "[23 / 30]   Val: Loss = 0.17812, Accuracy = 96.60%: 100%|██████████| 4/4 [00:00<00:00, 121.21it/s]\n",
      "[24 / 30] Train: Loss = 0.00105, Accuracy = 99.98%: 100%|██████████| 140/140 [00:01<00:00, 117.00it/s]\n",
      "[24 / 30]   Val: Loss = 0.17329, Accuracy = 96.80%: 100%|██████████| 4/4 [00:00<00:00, 133.32it/s]\n",
      "[25 / 30] Train: Loss = 0.00114, Accuracy = 99.98%: 100%|██████████| 140/140 [00:01<00:00, 116.75it/s]\n",
      "[25 / 30]   Val: Loss = 0.17255, Accuracy = 96.60%: 100%|██████████| 4/4 [00:00<00:00, 114.28it/s]\n",
      "[26 / 30] Train: Loss = 0.00070, Accuracy = 100.00%: 100%|██████████| 140/140 [00:01<00:00, 107.27it/s]\n",
      "[26 / 30]   Val: Loss = 0.16976, Accuracy = 96.80%: 100%|██████████| 4/4 [00:00<00:00, 108.11it/s]\n",
      "[27 / 30] Train: Loss = 0.00050, Accuracy = 100.00%: 100%|██████████| 140/140 [00:01<00:00, 96.85it/s]\n",
      "[27 / 30]   Val: Loss = 0.17467, Accuracy = 96.80%: 100%|██████████| 4/4 [00:00<00:00, 121.22it/s]\n",
      "[28 / 30] Train: Loss = 0.00043, Accuracy = 100.00%: 100%|██████████| 140/140 [00:01<00:00, 112.54it/s]\n",
      "[28 / 30]   Val: Loss = 0.18028, Accuracy = 96.60%: 100%|██████████| 4/4 [00:00<00:00, 129.03it/s]\n",
      "[29 / 30] Train: Loss = 0.00043, Accuracy = 100.00%: 100%|██████████| 140/140 [00:01<00:00, 111.11it/s]\n",
      "[29 / 30]   Val: Loss = 0.17291, Accuracy = 96.60%: 100%|██████████| 4/4 [00:00<00:00, 129.03it/s]\n",
      "[30 / 30] Train: Loss = 0.00047, Accuracy = 100.00%: 100%|██████████| 140/140 [00:01<00:00, 113.82it/s]\n",
      "[30 / 30]   Val: Loss = 0.18678, Accuracy = 97.20%: 100%|██████████| 4/4 [00:00<00:00, 133.34it/s]\n"
     ]
    }
   ],
   "source": [
    "model = IntentClassifierModel(vocab_size=len(tokens_field.vocab), intents_count=len(intent_field.vocab)).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "trainer = ModelTrainer(model, criterion, optimizer)\n",
    "\n",
    "fit(trainer, train_iter, epochs_count=30, val_iter=val_iter)\n",
    "\n",
    "torch.save(trainer, 'IntentClassifierModel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: Loss = 0.30393, Accuracy = 94.74%: 100%|██████████| 7/7 [00:00<00:00, 81.38it/s]\n"
     ]
    }
   ],
   "source": [
    "do_epoch(trainer, test_iter, is_train=False, name='Test:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8cb139c522e4819e3d090dc8ad216bec05e65d93fe5d3ba0b78a4e6871c48307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
