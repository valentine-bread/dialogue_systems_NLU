{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" �� ���� ����७��� ��� ���譥�\n",
      "��������, �ᯮ��塞�� �ணࠬ��� ��� ������ 䠩���.\n"
     ]
    }
   ],
   "source": [
    "# !pip -qq install torchtext==0.3.1\n",
    "# !git clone https://github.com/MiuLab/SlotGated-SLU.git\n",
    "!wget -qq https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week08_multitask/conlleval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Study\\Dialogue_systems\\env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch, random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor, LongTensor\n",
    "    DEVICE = torch.device('cuda:0')\n",
    "else:\n",
    "    from torch import FloatTensor, LongTensor\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size = 869\n",
      "Tags count = 121\n",
      "Intents count = 21\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "def read_dataset(path):\n",
    "    with open(os.path.join(path, 'seq.in')) as f_words, \\\n",
    "            open(os.path.join(path, 'seq.out')) as f_tags, \\\n",
    "            open(os.path.join(path, 'label')) as f_intents:\n",
    "        \n",
    "        return [\n",
    "            (words.strip().split(), tags.strip().split(), intent.strip()) \n",
    "            for words, tags, intent in zip(f_words, f_tags, f_intents)\n",
    "        ]\n",
    "train_data = read_dataset('SlotGated-SLU/data/atis/train/')\n",
    "val_data = read_dataset('SlotGated-SLU/data/atis/valid/')\n",
    "test_data = read_dataset('SlotGated-SLU/data/atis/test/')\n",
    "\n",
    "intent_to_example = {example[2]: example for example in train_data}\n",
    "# for example in intent_to_example.values():\n",
    "#     print('Intent:\\t', example[2])\n",
    "#     print('Text:\\t', '\\t'.join(example[0]))\n",
    "#     print('Tags:\\t', '\\t'.join(example[1]))\n",
    "#     print()\n",
    "    \n",
    "from torchtext.data import Field, LabelField, Example, Dataset, BucketIterator\n",
    "\n",
    "tokens_field = Field()\n",
    "tags_field = Field(unk_token=None)\n",
    "intent_field = LabelField()\n",
    "\n",
    "fields = [('tokens', tokens_field), ('tags', tags_field), ('intent', intent_field)]\n",
    "\n",
    "train_dataset = Dataset([Example.fromlist(example, fields) for example in train_data], fields)\n",
    "val_dataset = Dataset([Example.fromlist(example, fields) for example in val_data], fields)\n",
    "test_dataset = Dataset([Example.fromlist(example, fields) for example in test_data], fields)\n",
    "\n",
    "tokens_field.build_vocab(train_dataset)\n",
    "tags_field.build_vocab(train_dataset)\n",
    "intent_field.build_vocab(train_dataset)\n",
    "\n",
    "print('Vocab size =', len(tokens_field.vocab))\n",
    "print('Tags count =', len(tags_field.vocab))\n",
    "print('Intents count =', len(intent_field.vocab))\n",
    "\n",
    "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "    datasets=(train_dataset, val_dataset, test_dataset), batch_sizes=(32, 128, 128), \n",
    "    shuffle=True, device=DEVICE, sort=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenTaggerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, tags_count, emb_dim=64, lstm_hidden_dim=128, num_layers=2, dropout_p=0.25, pad_idx = 0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embeddings_layer = nn.Embedding(vocab_size, emb_dim, padding_idx = pad_idx)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.lstm_layer = nn.LSTM(input_size=emb_dim, hidden_size=lstm_hidden_dim, bidirectional=True, num_layers=num_layers, batch_first=True, dropout = dropout_p if num_layers > 1 else 0)\n",
    "        self.out_layer = nn.Linear(lstm_hidden_dim * 2, tags_count)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        projections =  self.dropout(self.embeddings_layer(inputs))\n",
    "        output_lstm, (_, _) = self.lstm_layer(projections)\n",
    "        \n",
    "        output = self.dropout(output_lstm)\n",
    "\n",
    "        output = self.out_layer(output)\n",
    "        # output = self.out_layer(output_lstm)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer_Trigger():\n",
    "    def __init__(self, model, criterion, optimizer, pad_idx):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "    def on_epoch_begin(self, is_train, name, batches_count):\n",
    "        \"\"\"\n",
    "        Initializes metrics\n",
    "        \"\"\"\n",
    "        self.epoch_loss = 0\n",
    "        self.correct_count, self.total_count = 0, 0\n",
    "        self.is_train = is_train\n",
    "        self.name = name\n",
    "        self.batches_count = batches_count\n",
    "        \n",
    "        self.model.train(is_train)\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Outputs final metrics\n",
    "        \"\"\"\n",
    "        return '{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "            self.name, self.epoch_loss / self.batches_count, self.correct_count / self.total_count\n",
    "        )\n",
    "        \n",
    "    def on_batch(self, batch):\n",
    "        \"\"\"\n",
    "        Performs forward and (if is_train) backward pass with optimization, updates metrics\n",
    "        \"\"\"\n",
    "        \n",
    "        logits = self.model(batch.tokens.transpose(0, 1))\n",
    "\n",
    "        logits = logits.transpose(0, 1)\n",
    "        \n",
    "        logits = logits.transpose(0, 1)\n",
    "        logits = logits.reshape((-1,logits.shape[2]))\n",
    "        tags = batch.tags.reshape((-1))\n",
    "        loss = self.criterion(logits, tags)\n",
    "\n",
    "        # loss = self.criterion(logits.reshape((-1,logits.shape[2])), batch.tags.reshape((-1)))\n",
    "        \n",
    "        # predicted_tags = logits.argmax(dim=1)\n",
    "        # non_pad_elements = (batch.tags != self.pad_idx)\n",
    "        \n",
    "        # print(predicted_tags.shape)\n",
    "        # print(predicted_tags.shape)\n",
    "        \n",
    "        \n",
    "        max_preds = logits.argmax(dim = 1) # get the index of the max probability получить индекс максимальной вероятности\n",
    "        non_pad_elements = (batch.tags != self.pad_idx).nonzero()\n",
    "        # print(max_preds[non_pad_elements].shape)\n",
    "        # print(tags[non_pad_elements].shape)\n",
    "        # correct  = max_preds[non_pad_elements].squeeze(1).eq(batch.tags [non_pad_elements])\n",
    "        # correct = torch.sum(torch.all(max_preds[non_pad_elements] == tags[non_pad_elements], axis=0)).item()\n",
    "        correct = torch.sum(max_preds[non_pad_elements].squeeze(1) == tags[non_pad_elements]).item()\n",
    "        self.total_count += batch.tags[non_pad_elements].shape[0]\n",
    "        self.correct_count += correct\n",
    "        \n",
    "\n",
    "        # predicted_tags = logits.argmax(dim=2)\n",
    "        # self.total_count += predicted_tags.shape[1] \n",
    "        # self.correct_count += torch.sum(torch.all(predicted_tags == batch.tags, axis=0)).item()\n",
    "        \n",
    "        # predicted_tags = logits.argmax(dim=2)\n",
    "        # non_pad_elements = (batch.tags != self.pad_idx).nonzero()\n",
    "        # self.total_count += batch.tags[non_pad_elements].shape[1]\n",
    "        # self.correct_count += torch.sum(torch.all(predicted_tags[non_pad_elements] == batch.tags[non_pad_elements], axis=0)).item()\n",
    "\n",
    "        if self.is_train:\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "        self.epoch_loss += loss.item()\n",
    "        \n",
    "import math\n",
    "from tqdm import tqdm\n",
    "tqdm.get_lock().locks = []\n",
    "\n",
    "\n",
    "def do_epoch(trainer, data_iter, is_train, name=None):\n",
    "    trainer.on_epoch_begin(is_train, name, batches_count=len(data_iter))\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        with tqdm(total=trainer.batches_count) as progress_bar:\n",
    "            for i, batch in enumerate(data_iter):\n",
    "                batch_progress = trainer.on_batch(batch)\n",
    "\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description(batch_progress)\n",
    "                \n",
    "            epoch_progress = trainer.on_epoch_end()\n",
    "            progress_bar.set_description(epoch_progress)\n",
    "            progress_bar.refresh()\n",
    "\n",
    "            \n",
    "def fit(trainer, train_iter, epochs_count=1, val_iter=None):\n",
    "    best_val_loss = None\n",
    "    for epoch in range(epochs_count):\n",
    "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
    "        do_epoch(trainer, train_iter, is_train=True, name=name_prefix + 'Train:')\n",
    "        \n",
    "        if not val_iter is None:\n",
    "            do_epoch(trainer, val_iter, is_train=False, name=name_prefix + '  Val:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/140 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_EXECUTION_FAILED",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters())\n\u001b[0;32m      8\u001b[0m trainer \u001b[39m=\u001b[39m ModelTrainer_Trigger(model, criterion, optimizer, pad_idx)\n\u001b[1;32m---> 10\u001b[0m fit(trainer, train_iter, epochs_count\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, val_iter\u001b[39m=\u001b[39;49mval_iter)\n\u001b[0;32m     12\u001b[0m torch\u001b[39m.\u001b[39msave(model, \u001b[39m'\u001b[39m\u001b[39mTokenTaggerModel.pt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [7], line 102\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(trainer, train_iter, epochs_count, val_iter)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs_count):\n\u001b[0;32m    101\u001b[0m     name_prefix \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m / \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m] \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, epochs_count)\n\u001b[1;32m--> 102\u001b[0m     do_epoch(trainer, train_iter, is_train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname_prefix \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mTrain:\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    104\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m val_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m         do_epoch(trainer, val_iter, is_train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name\u001b[39m=\u001b[39mname_prefix \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m  Val:\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [7], line 88\u001b[0m, in \u001b[0;36mdo_epoch\u001b[1;34m(trainer, data_iter, is_train, name)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(total\u001b[39m=\u001b[39mtrainer\u001b[39m.\u001b[39mbatches_count) \u001b[39mas\u001b[39;00m progress_bar:\n\u001b[0;32m     87\u001b[0m     \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data_iter):\n\u001b[1;32m---> 88\u001b[0m         batch_progress \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mon_batch(batch)\n\u001b[0;32m     90\u001b[0m         progress_bar\u001b[39m.\u001b[39mupdate()\n\u001b[0;32m     91\u001b[0m         progress_bar\u001b[39m.\u001b[39mset_description(batch_progress)\n",
      "Cell \u001b[1;32mIn [7], line 72\u001b[0m, in \u001b[0;36mModelTrainer_Trigger.on_batch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39m# predicted_tags = logits.argmax(dim=2)\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39m# self.total_count += predicted_tags.shape[1] \u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39m# self.correct_count += torch.sum(torch.all(predicted_tags == batch.tags, axis=0)).item()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39m# self.total_count += batch.tags[non_pad_elements].shape[1]\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[39m# self.correct_count += torch.sum(torch.all(predicted_tags[non_pad_elements] == batch.tags[non_pad_elements], axis=0)).item()\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_train:\n\u001b[1;32m---> 72\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     73\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     74\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Study\\Dialogue_systems\\env\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Study\\Dialogue_systems\\env\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED"
     ]
    }
   ],
   "source": [
    "pad_idx = tags_field.vocab.stoi['<pad>']\n",
    "\n",
    "model = TokenTaggerModel(vocab_size=len(tokens_field.vocab), tags_count=len(tags_field.vocab), pad_idx = pad_idx).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = pad_idx).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "trainer = ModelTrainer_Trigger(model, criterion, optimizer, pad_idx)\n",
    "\n",
    "fit(trainer, train_iter, epochs_count=30, val_iter=val_iter)\n",
    "\n",
    "torch.save(model, 'TokenTaggerModel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: Loss = 0.14732, Accuracy = 0.67%: 100%|██████████| 7/7 [00:00<00:00, 22.44it/s]\n"
     ]
    }
   ],
   "source": [
    "do_epoch(trainer, test_iter, is_train=False, name='Test:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 13.08%, Recall = 14.67%, F1 = 13.83%\n"
     ]
    }
   ],
   "source": [
    "from conlleval import evaluate\n",
    "\n",
    "def eval_tagger(model, test_iter):\n",
    "    true_seqs, pred_seqs = [], []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_iter:\n",
    "            # pred = do_epoch(trainer, batch, is_train=False, name='Test:')\n",
    "            pred = model.forward(batch.tokens.transpose(0, 1))\n",
    "            pred = pred.transpose(0, 1)\n",
    "            pred = pred.argmax(dim=2)\n",
    "            pred = list(map(lambda x: list(map(lambda y: tags_field.vocab.itos[y], x)), pred))\n",
    "            pred = list(map(lambda x: list(map(lambda y: y if y != '<pad>' else \"\", x)), pred))\n",
    "            pred = list(map(lambda x: ' '.join(x), pred))\n",
    "            pred = '\\n'.join(pred)\n",
    "                      \n",
    "            true = list(map(lambda x: list(map(lambda y: tags_field.vocab.itos[y], x)), batch.tags))\n",
    "            true = list(map(lambda x: list(map(lambda y: y if y != '<pad>' else \"\", x)), true))  \n",
    "            true = list(map(lambda x: ' '.join(x), true))\n",
    "            true = '\\n'.join(true)\n",
    "            \n",
    "            pred_seqs.append(pred)\n",
    "            true_seqs.append(true)\n",
    "    print('Precision = {:.2f}%, Recall = {:.2f}%, F1 = {:.2f}%'.format(*evaluate(true_seqs, pred_seqs, verbose=False)))\n",
    "\n",
    "eval_tagger(model, test_iter)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: Loss = 6.38924, Accuracy = 0.67%: 100%|██████████| 7/7 [00:00<00:00, 32.56it/s]\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('TokenTaggerModel.pt')\n",
    "\n",
    "pad_idx = tags_field.vocab.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "trainer = ModelTrainer_Trigger(model, criterion, optimizer, pad_idx)\n",
    "\n",
    "do_epoch(trainer, test_iter, is_train=False, name='Test:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_field.vocab.stoi['<pad>']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8cb139c522e4819e3d090dc8ad216bec05e65d93fe5d3ba0b78a4e6871c48307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
